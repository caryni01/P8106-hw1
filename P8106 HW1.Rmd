---
title: "P8106 HW1"
author: "Cary Ni"
date: "2023-02-09"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(glmnet)
library(caret)
library(corrplot)
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
```

# Prediction of sales prices of houses

```{r}
# load the datasets for model building
training_df = read_csv("housing_training.csv") %>% 
  janitor::clean_names() %>% 
  na.omit()
test_df = read_csv("housing_test.csv") %>% 
  janitor::clean_names() %>% 
  na.omit()
# create covariates matrix for training and test
predictors = model.matrix(sale_price ~ ., data = training_df)[,-1]
predictors_test = model.matrix(sale_price ~ ., data = test_df)[,-1]
# create response vector for training and test
response = training_df %>% pull(sale_price)
response_test = test_df %>% pull(sale_price)

# create a quick function to calculate test mse
get_test_mse = function(input_model, x_test, y_test) {
  predict_value = predict(input_model, newdata = x_test)
  test_mse = mean((predict_value - y_test)^2)
  return(test_mse)
}
```

## Correlation plot to check collinearity between covariates (based on training data)

```{r}
cor(predictors) %>% corrplot(
  method = "circle", type = "full", 
  addCoef.col = 1, number.font =0.5,
  tl.col="black", tl.srt=90, tl.cex = 0.5,
  insig = "blank", diag=FALSE, number.cex = .3)
```

It can be seen from the correlation plot that some are the covariates have high correlation coefficients to each to other, which leads to the issue of collinearity. In order to remedy for the potential multicollinearity among  covariates, regularization methods such as lasso, elastic net, and partial least squares are used to are used to minimize the influence brought by collinearity.

## Linear least squared model

```{r}
# set cross validation methods used in train object
ctrl_1 = trainControl(method = "repeatedcv", number = 10, repeats = 5)

set.seed(1)
# build the linear least squared model with caret
lm_model = train(predictors, response, method = "lm", trControl = ctrl_1)
summary(lm_model)
# get test mse of linear least squared model
get_test_mse(lm_model, predictors_test, response_test)
```

The least squared model has 38 variables shown above. 

## Lasso model based on lambda.min

```{r}
set.seed(1)
# build lasso model based on lambda.min
lasso_model_1 = train(predictors, response, 
                    method = "glmnet",
                    tuneGrid = expand.grid(alpha = 1,
                                           lambda = exp(seq(-2, 8, length=100))),
                    trControl = ctrl_1)
plot(lasso_model_1, xTrans = log)
# show the best lambda with lowest cv rmse
lasso_model_1$bestTune
# show coefficients of best model based on lambda min
coef(lasso_model_1$finalModel, lasso_model_1$bestTune$lambda)
# get test mse of lasso model based on lambda.min
get_test_mse(lasso_model_1, predictors_test, response_test)
# show number of predictors (excluding intercept)
num_coff = coef(lasso_model_1$finalModel, lasso_model_1$bestTune$lambda) 
sum(num_coff != 0) - 1
```

### Lasso model based on 1se rule

```{r}
# build lasso model based on lambda.1se
ctrl_2 = trainControl(method = "repeatedcv", selectionFunction = "oneSE",
                      number = 10, repeats = 5)
set.seed(1)
lasso_model_2 = train(predictors, response, 
                    method = "glmnet",
                    tuneGrid = expand.grid(alpha = 1,
                                           lambda = exp(seq(-2, 8, length=100))),
                    trControl = ctrl_2)
# show the best lambda based on 1se rule
lasso_model_2$bestTune
# show coefficients of best model based on 1se
coef(lasso_model_2$finalModel, lasso_model_2$bestTune$lambda)
# get test mse of lasso model based on 1se
get_test_mse(lasso_model_2, predictors_test, response_test)
# show number of predictors (excluding intercept)
num_coff_2 = coef(lasso_model_2$finalModel, lasso_model_2$bestTune$lambda) 
sum(num_coff_2 != 0) - 1
```

It can be seen that lambda.min generate a model with 37 predictors while 1se rule reduces number of predictors to 36.The selected lambda for lowest cv rmse is 62.89 while the 1se rule gives lambda of 372.1. Since the lasso model based on 1se rule has smaller test mse which is 4.21e8 than lambda.min which is 4.40e8, the lasso model based on 1se is favored. 

## Elastic net model

```{r}
set.seed(1)
# build elastic net model with caret
elnet_model = train(predictors, response, 
                    method = "glmnet",
                    tuneGrid = expand.grid(alpha = seq(0, 1, length=21),
                                           lambda = exp(seq(-2, 8, length=50))),
                    trControl = ctrl_1)
myCol<- rainbow(21)
myPar <- list(superpose.symbol = list(col = myCol),
superpose.line = list(col = myCol))
plot(elnet_model, par.settings = myPar)
# show the best lambda and alpha combination with lowest cv rmse
elnet_model$bestTune
# show coefficients of best model
coef(elnet_model$finalModel, elnet_model$bestTune$lambda)
# get test mse of the elastic net model
get_test_mse(elnet_model, predictors_test, response_test)
```

### Try Elastic net model with 1se

```{r}
set.seed(1)
elnet_model_2 = train(predictors, response, 
                    method = "glmnet",
                    tuneGrid = expand.grid(alpha = seq(0, 1, length=21),
                                           lambda = exp(seq(-2, 8, length=50))),
                    trControl = ctrl_2)
elnet_model_2$bestTune
# show coefficients of best model
coef(elnet_model_2$finalModel, elnet_model_2$bestTune$lambda)
```

The selected elastic net model with lowest cv rmse has best alpha = 0.05 and lambda = 582.5 shown above. The test mse of the model is 4.39e8. When 1se lambda is applied in this elastic net model, the best alpha becomes 0 and lambda is the largest value in the tuneGrid set (2980.96 in this case). It suggests that it becomes ridge regression and none of the parameters shrink to zero and fails to simplify the model. Therefore, applying 1se rule is not practical in selecting tuning parameters in this case. 

## Partial least squares model

```{r}
set.seed(1)
pls_model = train(predictors, response,
                method = "pls",
                tuneGrid = data.frame(ncomp = 1:19),
                trControl = ctrl_1,
                preProcess = c("center", "scale"))
ggplot(pls_model, highlight = TRUE) + 
  scale_x_continuous(breaks = seq(0,20,by=1))
# get test mse of the Partial least squares model
get_test_mse(pls_model, predictors_test, response_test)
```

It can shown that 12 components are included in the partial least squares model with lowest cv rmse. The test mse is 4.50e8.

## Compare the performance of models above

```{r}
# compare the model performance through resample method
resamp = resamples(
  list(
    least_square = lm_model,
    lasso = lasso_model_2,
    elastic_net = elnet_model,
    pls = pls_model))
summary(resamp)
bwplot(resamp, metric = "RMSE")
```

As shown in the summary statistics and boxplot above, the elastic net model gives lowest rmse and mean absolute error, and highest R squared value. Since lasso model fails to considerably reduce the number of predictors and partial least squares model is not favored in terms of intepretability, I would simply choose the elastic net model as the final predictive model for its predictive superiority. 
